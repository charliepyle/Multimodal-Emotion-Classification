{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "micro-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as util\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-guyana",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optical-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels, lexical_data, acoustic_data, visual_data = [], [], [], []\n",
    "reader = csv.reader(open(\"dataset.csv\"), delimiter=',')\n",
    "next(reader)\n",
    "\n",
    "for row in reader:\n",
    "    visual_data.append(np.load(row[2][1:]))\n",
    "    acoustic_data.append(np.load(row[3][1:]))\n",
    "    lexical_data.append(np.load(row[4][1:]))\n",
    "    data_labels.append(int(row[5]))\n",
    "\n",
    "# Labels\n",
    "data_labels = torch.from_numpy(np.asarray(data_labels))\n",
    "\n",
    " \n",
    "# Lexical Data\n",
    "lexical_data = torch.from_numpy(np.asarray(lexical_data))\n",
    "lexical_dataset = util.data.TensorDataset(lexical_data, data_labels)\n",
    "\n",
    "# Acoustic Data - first pad, then convert into tensor\n",
    "acoustic_max = max([len(tens) for tens in acoustic_data])\n",
    "for i, tens in enumerate(acoustic_data):\n",
    "    dist = acoustic_max - len(tens)\n",
    "    tens = np.pad(tens, pad_width=[(0,dist), (0,0)], mode='constant')\n",
    "    acoustic_data[i] = tens\n",
    "    \n",
    "acoustic_data = torch.from_numpy(np.asarray(acoustic_data))\n",
    "acoustic_dataset = util.data.TensorDataset(acoustic_data, data_labels)\n",
    "\n",
    "\n",
    "# Visual Data - first pad, then convert into tensor\n",
    "visual_max = max([len(tens) for tens in visual_data])\n",
    "for i, tens in enumerate(visual_data):\n",
    "    dist = visual_max - len(tens)\n",
    "    tens = np.pad(tens, pad_width=[(0,dist), (0,0)], mode='constant')\n",
    "    visual_data[i] = tens\n",
    "    \n",
    "visual_data = torch.from_numpy(np.asarray(visual_data)).type('torch.DoubleTensor') # need to explicitly cast as double\n",
    "visual_dataset = util.data.TensorDataset(visual_data, data_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "falling-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "previous-difference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual Data Shape: torch.Size([1336, 716, 2048])\n",
      "Acoustic Data Shape: torch.Size([1336, 24, 128])\n",
      "Lexical Data Shape: torch.Size([1336, 768])\n",
      "Labels Shape: torch.Size([1336])\n"
     ]
    }
   ],
   "source": [
    "print('Visual Data Shape: ' + str(visual_data.shape))\n",
    "print('Acoustic Data Shape: ' +  str(acoustic_data.shape))\n",
    "print('Lexical Data Shape: ' +  str(lexical_data.shape))\n",
    "print('Labels Shape: ' +  str(data_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-tuner",
   "metadata": {},
   "source": [
    "# Lexical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-recipient",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alpine-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexicalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LexicalModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 230)\n",
    "        self.batch1 = nn.BatchNorm1d(230)\n",
    "        self.fc2 = nn.Linear(230, 50)\n",
    "        self.batch2 = nn.BatchNorm1d(50)\n",
    "        self.fc3 = nn.Linear(50, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "      \n",
    "    # batchnorm wrecks this for some reason\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "#         x = self.batch1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "#         x = self.batch2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-liabilities",
   "metadata": {},
   "source": [
    "## Training and Testing Lexical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "instrumental-election",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 0: 63 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Average: 63.43283582089553 %\n",
      "Fold 1\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 1: 78 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Average: 70.8955223880597 %\n",
      "Fold 2\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 2: 90 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Average: 77.363184079602 %\n",
      "Fold 3\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 3: 96 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Fold 3: 96.26865671641791 %\n",
      "Average: 82.08955223880598 %\n",
      "Fold 4\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 4: 96 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Fold 3: 96.26865671641791 %\n",
      "Fold 4: 96.26865671641791 %\n",
      "Average: 84.92537313432837 %\n",
      "Fold 5\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 5: 97 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Fold 3: 96.26865671641791 %\n",
      "Fold 4: 96.26865671641791 %\n",
      "Fold 5: 97.76119402985076 %\n",
      "Average: 87.06467661691543 %\n",
      "Fold 6\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 6: 93 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Fold 3: 96.26865671641791 %\n",
      "Fold 4: 96.26865671641791 %\n",
      "Fold 5: 97.76119402985076 %\n",
      "Fold 6: 93.98496240601504 %\n",
      "Average: 88.05328887250108 %\n",
      "Fold 7\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 7: 96 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Fold 3: 96.26865671641791 %\n",
      "Fold 4: 96.26865671641791 %\n",
      "Fold 5: 97.76119402985076 %\n",
      "Fold 6: 93.98496240601504 %\n",
      "Fold 7: 96.99248120300751 %\n",
      "Average: 89.17068791381439 %\n",
      "Fold 8\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 8: 91 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Fold 3: 96.26865671641791 %\n",
      "Fold 4: 96.26865671641791 %\n",
      "Fold 5: 97.76119402985076 %\n",
      "Fold 6: 93.98496240601504 %\n",
      "Fold 7: 96.99248120300751 %\n",
      "Fold 8: 91.72932330827066 %\n",
      "Average: 89.45498073542063 %\n",
      "Fold 9\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 9: 94 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 63.43283582089553 %\n",
      "Fold 1: 78.35820895522389 %\n",
      "Fold 2: 90.29850746268657 %\n",
      "Fold 3: 96.26865671641791 %\n",
      "Fold 4: 96.26865671641791 %\n",
      "Fold 5: 97.76119402985076 %\n",
      "Fold 6: 93.98496240601504 %\n",
      "Fold 7: 96.99248120300751 %\n",
      "Fold 8: 91.72932330827066 %\n",
      "Fold 9: 94.73684210526315 %\n",
      "Average: 89.9831668724049 %\n"
     ]
    }
   ],
   "source": [
    "lex = LexicalModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lex.parameters(), lr=1e-4)\n",
    "\n",
    "k_folds = 10\n",
    "num_epochs = 20\n",
    "\n",
    "k_fold_results = {}\n",
    "\n",
    "total_lexical_predicted, total_lexical_targets = [], []\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(lexical_dataset)):\n",
    "    print(f\"Fold {fold}\")\n",
    "    print('----------------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    lexical_trainloader = torch.utils.data.DataLoader(lexical_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    lexical_testloader = torch.utils.data.DataLoader(lexical_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(lexical_trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = lex(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "#             if i % 100 == 99:    # print every 200 mini-batches\n",
    "#                 print('[%d, %5d] loss: %.3f' %\n",
    "#                       (epoch + 1, i + 1, running_loss / 100))\n",
    "#                 running_loss = 0.0\n",
    "\n",
    "    print('Finished Training - Testing Begins')\n",
    "    \n",
    "    correct, total = 0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(lexical_testloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Generate outputs\n",
    "            outputs = lex(inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            \n",
    "            total_lexical_predicted += predicted\n",
    "            total_lexical_targets += targets\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        k_fold_results[fold] = 100.0 * (correct / total)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in k_fold_results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(k_fold_results.items())} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-ottawa",
   "metadata": {},
   "source": [
    "## Lexical Results with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "republican-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Confusion Matrix with F1 Score: 0.8997005988023952\n",
      "--------------------------------\n",
      "Confusion matrix, without normalization\n",
      "[[303   2   3  20]\n",
      " [  5 266  10  27]\n",
      " [  1   7 150  22]\n",
      " [ 15  14   8 483]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lexical_f1 = f1_score(total_lexical_targets, total_lexical_predicted, average='micro')\n",
    "lexical_cm = confusion_matrix(total_lexical_targets, total_lexical_predicted)\n",
    "\n",
    "# probably a better way to do this\n",
    "classes = np.ndarray([0,1,2,3])\n",
    "\n",
    "print(f'Lexical Confusion Matrix with F1 Score: {lexical_f1}')\n",
    "print('--------------------------------')\n",
    "plot_confusion_matrix(lexical_cm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-briefing",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Acoustic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "center-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcousticModel(nn.Module):\n",
    "    def __init__(self, pool_size):\n",
    "        super(AcousticModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=24, kernel_size=1, out_channels=16)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, kernel_size=1, out_channels=8)\n",
    "        self.pool1 = nn.MaxPool1d(pool_size, stride=pool_size)\n",
    "#         self.pool1 = nn.AvgPool1d(pool_size, stride=pool_size)\n",
    "    \n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.batch1 = nn.BatchNorm1d(16)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.batch2 = nn.BatchNorm1d(8)\n",
    "        self.fc3 = nn.Linear(16, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "      \n",
    "    # batchnorm wrecks this for some reason\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "#         print(x.shape)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "#         x = self.batch1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "#         x = self.batch2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-vulnerability",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training And Testing Acoustic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "relative-pleasure",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 0: 46 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Average: 46.26865671641791 %\n",
      "Fold 1\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 1: 54 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Average: 50.373134328358205 %\n",
      "Fold 2\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 2: 58 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Average: 52.98507462686567 %\n",
      "Fold 3\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 3: 51 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Fold 3: 51.49253731343284 %\n",
      "Average: 52.61194029850746 %\n",
      "Fold 4\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 4: 66 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Fold 3: 51.49253731343284 %\n",
      "Fold 4: 66.4179104477612 %\n",
      "Average: 55.373134328358205 %\n",
      "Fold 5\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 5: 54 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Fold 3: 51.49253731343284 %\n",
      "Fold 4: 66.4179104477612 %\n",
      "Fold 5: 54.47761194029851 %\n",
      "Average: 55.223880597014926 %\n",
      "Fold 6\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 6: 55 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Fold 3: 51.49253731343284 %\n",
      "Fold 4: 66.4179104477612 %\n",
      "Fold 5: 54.47761194029851 %\n",
      "Fold 6: 55.639097744360896 %\n",
      "Average: 55.28319733235006 %\n",
      "Fold 7\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 7: 56 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Fold 3: 51.49253731343284 %\n",
      "Fold 4: 66.4179104477612 %\n",
      "Fold 5: 54.47761194029851 %\n",
      "Fold 6: 55.639097744360896 %\n",
      "Fold 7: 56.390977443609025 %\n",
      "Average: 55.42166984625743 %\n",
      "Fold 8\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 8: 63 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Fold 3: 51.49253731343284 %\n",
      "Fold 4: 66.4179104477612 %\n",
      "Fold 5: 54.47761194029851 %\n",
      "Fold 6: 55.639097744360896 %\n",
      "Fold 7: 56.390977443609025 %\n",
      "Fold 8: 63.1578947368421 %\n",
      "Average: 56.281250389655725 %\n",
      "Fold 9\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 9: 57 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 46.26865671641791 %\n",
      "Fold 1: 54.47761194029851 %\n",
      "Fold 2: 58.2089552238806 %\n",
      "Fold 3: 51.49253731343284 %\n",
      "Fold 4: 66.4179104477612 %\n",
      "Fold 5: 54.47761194029851 %\n",
      "Fold 6: 55.639097744360896 %\n",
      "Fold 7: 56.390977443609025 %\n",
      "Fold 8: 63.1578947368421 %\n",
      "Fold 9: 57.14285714285714 %\n",
      "Average: 56.36741106497586 %\n"
     ]
    }
   ],
   "source": [
    "acoust = AcousticModel(pool_size=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(acoust.parameters(), lr=1e-4)\n",
    "\n",
    "k_folds = 10\n",
    "num_epochs = 20\n",
    "\n",
    "total_acoustic_predicted, total_acoustic_targets = [], []\n",
    "\n",
    "k_fold_results = {}\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(acoustic_dataset)):\n",
    "    print(f\"Fold {fold}\")\n",
    "    print('----------------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    acoustic_trainloader = torch.utils.data.DataLoader(acoustic_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    acoustic_testloader = torch.utils.data.DataLoader(acoustic_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(acoustic_trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = acoust(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "#             if i % 100 == 99:    # print every 200 mini-batches\n",
    "#                 print('[%d, %5d] loss: %.3f' %\n",
    "#                       (epoch + 1, i + 1, running_loss / 100))\n",
    "#                 running_loss = 0.0\n",
    "\n",
    "    print('Finished Training - Testing Begins')\n",
    "    \n",
    "    correct, total = 0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(acoustic_testloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Generate outputs\n",
    "            outputs = acoust(inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total_acoustic_predicted += predicted\n",
    "            total_acoustic_targets += targets\n",
    "            \n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        k_fold_results[fold] = 100.0 * (correct / total)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in k_fold_results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(k_fold_results.items())} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-welding",
   "metadata": {},
   "source": [
    "## Acoustic Results with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "geographic-identification",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acoustic Confusion Matrix with F1 Score: 0.563622754491018\n",
      "--------------------------------\n",
      "Confusion matrix, without normalization\n",
      "[[207  11   2 108]\n",
      " [ 19 176   2 111]\n",
      " [ 40  34   2 104]\n",
      " [ 70  80   2 368]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acoustic_f1 = f1_score(total_acoustic_targets, total_acoustic_predicted, average='micro')\n",
    "acoustic_cm = confusion_matrix(total_acoustic_targets, total_acoustic_predicted)\n",
    "\n",
    "# probably a better way to do this\n",
    "classes = np.ndarray([0,1,2,3])\n",
    "\n",
    "print(f'Acoustic Confusion Matrix with F1 Score: {acoustic_f1}')\n",
    "print('--------------------------------')\n",
    "plot_confusion_matrix(acoustic_cm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-quest",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "offensive-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualModel(nn.Module):\n",
    "    def __init__(self, pool_1_size, pool_2_size):\n",
    "        super(VisualModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=716, kernel_size=1, out_channels=8).double()\n",
    "        self.batch1 = nn.BatchNorm1d(8)\n",
    "        self.pool1 = nn.MaxPool1d(pool_1_size, stride=pool_1_size)\n",
    "        self.pool2 = nn.MaxPool1d(pool_2_size, stride=pool_2_size)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, kernel_size=1, out_channels=1).double()\n",
    "        self.batch2 = nn.BatchNorm1d(1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        \n",
    "        self.fc3 = nn.Linear(16, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "#         print(x.shape)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "#         print(x.shape)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-polls",
   "metadata": {},
   "source": [
    "## Training and Testing Visual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "accredited-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 0: 29 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Average: 29.1044776119403 %\n",
      "Fold 1\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 1: 39 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Average: 34.32835820895522 %\n",
      "Fold 2\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 2: 44 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Average: 37.81094527363184 %\n",
      "Fold 3\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 3: 44 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Fold 3: 44.02985074626866 %\n",
      "Average: 39.365671641791046 %\n",
      "Fold 4\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 4: 50 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Fold 3: 44.02985074626866 %\n",
      "Fold 4: 50.0 %\n",
      "Average: 41.492537313432834 %\n",
      "Fold 5\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 5: 65 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Fold 3: 44.02985074626866 %\n",
      "Fold 4: 50.0 %\n",
      "Fold 5: 65.67164179104478 %\n",
      "Average: 45.52238805970149 %\n",
      "Fold 6\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 6: 63 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Fold 3: 44.02985074626866 %\n",
      "Fold 4: 50.0 %\n",
      "Fold 5: 65.67164179104478 %\n",
      "Fold 6: 63.1578947368421 %\n",
      "Average: 48.04174615643586 %\n",
      "Fold 7\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 7: 63 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Fold 3: 44.02985074626866 %\n",
      "Fold 4: 50.0 %\n",
      "Fold 5: 65.67164179104478 %\n",
      "Fold 6: 63.1578947368421 %\n",
      "Fold 7: 63.1578947368421 %\n",
      "Average: 49.93126472898664 %\n",
      "Fold 8\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 8: 70 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Fold 3: 44.02985074626866 %\n",
      "Fold 4: 50.0 %\n",
      "Fold 5: 65.67164179104478 %\n",
      "Fold 6: 63.1578947368421 %\n",
      "Fold 7: 63.1578947368421 %\n",
      "Fold 8: 70.67669172932331 %\n",
      "Average: 52.23631217346849 %\n",
      "Fold 9\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 9: 74 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 29.1044776119403 %\n",
      "Fold 1: 39.55223880597015 %\n",
      "Fold 2: 44.776119402985074 %\n",
      "Fold 3: 44.02985074626866 %\n",
      "Fold 4: 50.0 %\n",
      "Fold 5: 65.67164179104478 %\n",
      "Fold 6: 63.1578947368421 %\n",
      "Fold 7: 63.1578947368421 %\n",
      "Fold 8: 70.67669172932331 %\n",
      "Fold 9: 74.43609022556392 %\n",
      "Average: 54.456289978678036 %\n"
     ]
    }
   ],
   "source": [
    "visual = VisualModel(pool_1_size=8, pool_2_size=4).double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(visual.parameters(), lr=1e-4)\n",
    "\n",
    "k_folds = 10\n",
    "num_epochs = 10\n",
    "\n",
    "total_visual_predicted, total_visual_targets = [], []\n",
    "\n",
    "k_fold_results = {}\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(visual_dataset)):\n",
    "    print(f\"Fold {fold}\")\n",
    "    print('----------------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    visual_trainloader = torch.utils.data.DataLoader(visual_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    visual_testloader = torch.utils.data.DataLoader(visual_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(visual_trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = visual(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "#             print(i)\n",
    "            \n",
    "#             if i % 100 == 99:    # print every 200 mini-batches\n",
    "#                 print('[%d, %5d] loss: %.3f' %\n",
    "#                       (epoch + 1, i + 1, running_loss / 100))\n",
    "#                 running_loss = 0.0\n",
    "\n",
    "    print('Finished Training - Testing Begins')\n",
    "    \n",
    "    correct, total = 0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(visual_testloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Generate outputs\n",
    "            outputs = visual(inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total_visual_predicted += predicted\n",
    "            total_visual_targets += targets\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        k_fold_results[fold] = 100.0 * (correct / total)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in k_fold_results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(k_fold_results.items())} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-hudson",
   "metadata": {},
   "source": [
    "## Visual Results and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "prescribed-refund",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Confusion Matrix with F1 Score: 0.8787425149700597\n",
      "--------------------------------\n",
      "Confusion matrix, without normalization\n",
      "[[298   6   2  22]\n",
      " [  6 271   4  27]\n",
      " [  3   8 140  29]\n",
      " [ 16  27  12 465]]\n",
      "\n",
      "Acoustic Confusion Matrix with F1 Score: 0.6002994011976048\n",
      "--------------------------------\n",
      "Confusion matrix, without normalization\n",
      "[[187  20   3 118]\n",
      " [ 10 201   4  93]\n",
      " [ 31  28  14 107]\n",
      " [ 58  56   6 400]]\n",
      "\n",
      "Visual Confusion Matrix with F1 Score: 0.5441616766467066\n",
      "--------------------------------\n",
      "Confusion matrix, without normalization\n",
      "[[113  48  16 151]\n",
      " [ 42 131  16 119]\n",
      " [ 35  38  44  63]\n",
      " [ 43  30   8 439]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrices and F1-Micro Scores\n",
    "visual_f1 = f1_score(total_visual_targets, total_visual_predicted, average='micro')\n",
    "visual_cm = confusion_matrix(total_visual_targets, total_visual_predicted)\n",
    "\n",
    "classes = np.ndarray([0,1,2,3])\n",
    "\n",
    "print(f'Visual Confusion Matrix with F1 Score: {visual_f1}')\n",
    "print('--------------------------------')\n",
    "plot_confusion_matrix(visual_cm, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-founder",
   "metadata": {},
   "source": [
    "## Early Fusion Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "israeli-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyFusionModel(nn.Module):\n",
    "    def __init__(self, acoustic_pool_size, visual_pool_1_size, visual_pool_2_size):\n",
    "        super(EarlyFusionModel, self).__init__()\n",
    "        \n",
    "        # Lexical Section\n",
    "        \n",
    "        self.fc1 = nn.Linear(1088, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Acoustic Section\n",
    "        \n",
    "        self.acoustic_conv1 = nn.Conv1d(in_channels=24, kernel_size=1, out_channels=16).float()\n",
    "        self.acoustic_conv2 = nn.Conv1d(in_channels=16, kernel_size=1, out_channels=8).float()\n",
    "        self.acoustic_pool1 = nn.MaxPool1d(acoustic_pool_size, stride=acoustic_pool_size)\n",
    "        self.acoustic_batch1 = nn.BatchNorm1d(16)\n",
    "        self.acoustic_batch2 = nn.BatchNorm1d(8)\n",
    "        \n",
    "        # Visual Section\n",
    "        \n",
    "        self.visual_conv1 = nn.Conv1d(in_channels=716, kernel_size=1, out_channels=8).double()\n",
    "        self.visual_batch1 = nn.BatchNorm1d(8)\n",
    "        self.visual_pool1 = nn.MaxPool1d(visual_pool_1_size, stride=visual_pool_1_size)\n",
    "        self.visual_pool2 = nn.MaxPool1d(visual_pool_2_size, stride=visual_pool_2_size)\n",
    "        self.visual_conv2 = nn.Conv1d(in_channels=8, kernel_size=1, out_channels=1).double()\n",
    "        self.visual_batch2 = nn.BatchNorm1d(1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "      \n",
    "    def forward(self, lexical, acoustic, visual):\n",
    "        # Performs Convolutional layers on Acoustic and Visual data, then flattens and connects with Lexical Data for fully connected network\n",
    "        \n",
    "        # Acoustic Section\n",
    "        \n",
    "        acoustic = self.acoustic_conv1(acoustic.double())\n",
    "        acoustic = self.acoustic_batch1(acoustic)\n",
    "        acoustic = self.relu(acoustic)\n",
    "        acoustic = self.acoustic_pool1(acoustic)\n",
    "        acoustic = self.dropout(acoustic)\n",
    "        \n",
    "        acoustic = self.acoustic_conv2(acoustic)\n",
    "        acoustic = self.acoustic_batch2(acoustic)\n",
    "        acoustic = self.relu(acoustic)\n",
    "        acoustic = self.acoustic_pool1(acoustic)\n",
    "        \n",
    "        acoustic = self.flatten(acoustic)\n",
    "        \n",
    "        # Visual Section\n",
    "        \n",
    "        visual = self.visual_conv1(visual)\n",
    "        visual = self.visual_batch1(visual)\n",
    "        visual = self.relu(visual)\n",
    "        visual = self.visual_pool1(visual)\n",
    "        \n",
    "        visual = self.dropout(visual)\n",
    "        \n",
    "        visual = self.visual_conv2(visual)\n",
    "        visual = self.visual_batch2(visual)\n",
    "        visual = self.relu(visual)\n",
    "        visual = self.visual_pool2(visual)\n",
    "        \n",
    "        visual = self.flatten(visual)\n",
    "        \n",
    "        # Combine\n",
    "        combined = torch.cat([lexical, acoustic, visual],dim=1)\n",
    "        \n",
    "        combined = self.fc1(combined)\n",
    "        combined = self.relu(combined)\n",
    "        combined = self.dropout(combined)\n",
    "        \n",
    "        combined = self.fc2(combined)\n",
    "        combined = self.relu(combined)\n",
    "        \n",
    "        combined = self.fc3(combined)\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-adoption",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training and Testing Early Fusion MM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "expanded-delaware",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 0: 53 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 53.73134328358209 %\n",
      "Average: 53.73134328358209 %\n",
      "Fold 1\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 1: 46 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 53.73134328358209 %\n",
      "Fold 1: 46.26865671641791 %\n",
      "Average: 50.0 %\n",
      "Fold 2\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 2: 61 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 53.73134328358209 %\n",
      "Fold 1: 46.26865671641791 %\n",
      "Fold 2: 61.940298507462686 %\n",
      "Average: 53.980099502487555 %\n",
      "Fold 3\n",
      "----------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-c77a39fa0535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#         print(type(combined_trainloader.dataset))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlexical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macoustic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexical_trainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macoustic_trainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_trainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_multi = EarlyFusionModel(acoustic_pool_size=2,visual_pool_1_size=8, visual_pool_2_size=4).double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(early_multi.parameters(), lr=1e-4)\n",
    "\n",
    "k_folds = 10\n",
    "num_epochs = 5\n",
    "\n",
    "total_combined_predicted, total_combined_targets = [], []\n",
    "\n",
    "k_fold_results = {}\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(visual_dataset)):\n",
    "    print(f\"Fold {fold}\")\n",
    "    print('----------------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    visual_trainloader = torch.utils.data.DataLoader(visual_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    visual_testloader = torch.utils.data.DataLoader(visual_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    acoustic_trainloader = torch.utils.data.DataLoader(acoustic_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    acoustic_testloader = torch.utils.data.DataLoader(acoustic_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    lexical_trainloader = torch.utils.data.DataLoader(lexical_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    lexical_testloader = torch.utils.data.DataLoader(lexical_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "#         print(type(combined_trainloader.dataset))\n",
    "        running_loss = 0.0\n",
    "        for lexical, acoustic, visual in zip(lexical_trainloader, acoustic_trainloader, visual_trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            lexical_data, lexical_label = lexical\n",
    "            acoustic_data, acoustic_label = acoustic\n",
    "            visual_data, visual_label = visual\n",
    "            \n",
    "            \n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            # Generate outputs\n",
    "            outputs = early_multi(lexical_data, acoustic_data, visual_data)\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            loss = criterion(outputs, lexical_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 99:    # print every 200 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training - Testing Begins')\n",
    "    \n",
    "    correct, total = 0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for lexical, acoustic, visual in zip(lexical_testloader, acoustic_testloader, visual_testloader):\n",
    "\n",
    "            # Get inputs\n",
    "            lexical_data, lexical_label = lexical\n",
    "            acoustic_data, acoustic_label = acoustic\n",
    "            visual_data, visual_label = visual\n",
    "            \n",
    "            \n",
    "            # Generate outputs\n",
    "            outputs = early_multi(lexical_data, acoustic_data, visual_data)\n",
    "            \n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total_combined_predicted += predicted\n",
    "            total_combined_targets += lexical_label\n",
    "            \n",
    "            total += lexical_label.size(0)\n",
    "            correct += (predicted == lexical_label).sum().item()\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        k_fold_results[fold] = 100.0 * (correct / total)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in k_fold_results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(k_fold_results.items())} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-champagne",
   "metadata": {},
   "source": [
    "## Early Fusion Results and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices and F1-Micro Scores\n",
    "early_f1 = f1_score(total_combined_targets, total_combined_predicted, average='micro')\n",
    "early_cm = confusion_matrix(total_combined_targets, total_combined_predicted)\n",
    "\n",
    "classes = np.ndarray([0,1,2,3])\n",
    "\n",
    "print(f'Early Fusion Confusion Matrix with F1 Score: {early_f1}')\n",
    "print('--------------------------------')\n",
    "plot_confusion_matrix(early_cm, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-imperial",
   "metadata": {},
   "source": [
    "## Late Fusion Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "computational-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 0: 42 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Average: 42.53731343283582 %\n",
      "Fold 1\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 1: 53 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Average: 48.13432835820896 %\n",
      "Fold 2\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 2: 62 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Average: 52.985074626865675 %\n",
      "Fold 3\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 3: 71 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Fold 3: 71.64179104477611 %\n",
      "Average: 57.649253731343286 %\n",
      "Fold 4\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 4: 70 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Fold 3: 71.64179104477611 %\n",
      "Fold 4: 70.1492537313433 %\n",
      "Average: 60.149253731343286 %\n",
      "Fold 5\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 5: 67 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Fold 3: 71.64179104477611 %\n",
      "Fold 4: 70.1492537313433 %\n",
      "Fold 5: 67.16417910447761 %\n",
      "Average: 61.31840796019901 %\n",
      "Fold 6\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 6: 69 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Fold 3: 71.64179104477611 %\n",
      "Fold 4: 70.1492537313433 %\n",
      "Fold 5: 67.16417910447761 %\n",
      "Fold 6: 69.17293233082707 %\n",
      "Average: 62.44048287028873 %\n",
      "Fold 7\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 7: 72 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Fold 3: 71.64179104477611 %\n",
      "Fold 4: 70.1492537313433 %\n",
      "Fold 5: 67.16417910447761 %\n",
      "Fold 6: 69.17293233082707 %\n",
      "Fold 7: 72.18045112781954 %\n",
      "Average: 63.65797890248008 %\n",
      "Fold 8\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 8: 77 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Fold 3: 71.64179104477611 %\n",
      "Fold 4: 70.1492537313433 %\n",
      "Fold 5: 67.16417910447761 %\n",
      "Fold 6: 69.17293233082707 %\n",
      "Fold 7: 72.18045112781954 %\n",
      "Fold 8: 77.44360902255639 %\n",
      "Average: 65.18971558248856 %\n",
      "Fold 9\n",
      "----------------------------\n",
      "Finished Training - Testing Begins\n",
      "Accuracy for fold 9: 77 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 42.53731343283582 %\n",
      "Fold 1: 53.73134328358209 %\n",
      "Fold 2: 62.68656716417911 %\n",
      "Fold 3: 71.64179104477611 %\n",
      "Fold 4: 70.1492537313433 %\n",
      "Fold 5: 67.16417910447761 %\n",
      "Fold 6: 69.17293233082707 %\n",
      "Fold 7: 72.18045112781954 %\n",
      "Fold 8: 77.44360902255639 %\n",
      "Fold 9: 77.44360902255639 %\n",
      "Average: 66.41510492649535 %\n"
     ]
    }
   ],
   "source": [
    "lex = LexicalModel()\n",
    "acoust = AcousticModel(pool_size=2)\n",
    "visual = VisualModel(pool_1_size=8, pool_2_size=4).double()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lex_optimizer = optim.Adam(lex.parameters(), lr=1e-4)\n",
    "acoust_optimizer = optim.Adam(acoust.parameters(), lr=1e-4)\n",
    "visual_optimizer = optim.Adam(visual.parameters(), lr=1e-4)\n",
    "\n",
    "k_folds = 10\n",
    "num_epochs = 10\n",
    "\n",
    "late_combined_predicted, late_combined_targets = [], []\n",
    "\n",
    "k_fold_results = {}\n",
    "\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(visual_dataset)): # arbitrarily pick visual\n",
    "    print(f\"Fold {fold}\")\n",
    "    print('----------------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    visual_trainloader = torch.utils.data.DataLoader(visual_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    visual_testloader = torch.utils.data.DataLoader(visual_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    acoustic_trainloader = torch.utils.data.DataLoader(acoustic_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    acoustic_testloader = torch.utils.data.DataLoader(acoustic_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    lexical_trainloader = torch.utils.data.DataLoader(lexical_dataset, batch_size=10,\n",
    "                                          sampler=train_subsampler)\n",
    "    lexical_testloader = torch.utils.data.DataLoader(lexical_dataset, batch_size=10,\n",
    "                                          sampler=test_subsampler)\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "#         print(type(combined_trainloader.dataset))\n",
    "        running_loss = 0.0\n",
    "        for lexical, acoustic, vis in zip(lexical_trainloader, acoustic_trainloader, visual_trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            lexical_data, lexical_label = lexical\n",
    "            acoustic_data, acoustic_label = acoustic\n",
    "            visual_data, visual_label = vis\n",
    "            \n",
    "            \n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            lex_optimizer.zero_grad()\n",
    "            acoust_optimizer.zero_grad()\n",
    "            visual_optimizer.zero_grad()\n",
    "            \n",
    "            # Generate outputs\n",
    "            lex_outputs = lex(lexical_data)\n",
    "            acoust_outputs = acoust(acoustic_data)\n",
    "            visual_outputs = visual(visual_data)\n",
    "\n",
    "            \n",
    "            \n",
    "            #lexical \n",
    "            # forward + backward + optimize\n",
    "            lex_loss = criterion(lex_outputs, lexical_label)\n",
    "            lex_loss.backward()\n",
    "            lex_optimizer.step()\n",
    "            \n",
    "            acoust_loss = criterion(acoust_outputs, acoustic_label)\n",
    "            acoust_loss.backward()\n",
    "            acoust_optimizer.step()\n",
    "            \n",
    "            visual_loss = criterion(visual_outputs, visual_label)\n",
    "            visual_loss.backward()\n",
    "            visual_optimizer.step()\n",
    "            \n",
    "            \n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 99:    # print every 200 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training - Testing Begins')\n",
    "    \n",
    "    correct, total = 0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for lexical, acoustic, vis in zip(lexical_testloader, acoustic_testloader, visual_testloader):\n",
    "\n",
    "            # Get inputs\n",
    "            lexical_data, lexical_label = lexical\n",
    "            acoustic_data, acoustic_label = acoustic\n",
    "            visual_data, visual_label = vis\n",
    "            \n",
    "            \n",
    "            # Generate outputs\n",
    "            lex_outputs = lex(lexical_data)\n",
    "            acoust_outputs = acoust(acoustic_data)\n",
    "            visual_outputs = visual(visual_data)\n",
    "            \n",
    "            total_outputs = lex_outputs + acoust_outputs + visual_outputs\n",
    "            \n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(total_outputs.data, 1)\n",
    "            \n",
    "            late_combined_predicted += predicted\n",
    "            late_combined_targets += lexical_label\n",
    "            \n",
    "            total += lexical_label.size(0)\n",
    "            correct += (predicted == lexical_label).sum().item()\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        k_fold_results[fold] = 100.0 * (correct / total)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print('--------------------------------')\n",
    "    sum = 0.0\n",
    "    for key, value in k_fold_results.items():\n",
    "        print(f'Fold {key}: {value} %')\n",
    "        sum += value\n",
    "    print(f'Average: {sum/len(k_fold_results.items())} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-overall",
   "metadata": {},
   "source": [
    "## Late Fusion Results with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices and F1-Micro Scores\n",
    "late_f1 = f1_score(late_combined_predicted, late_combined_predicted, average='micro')\n",
    "late_cm = confusion_matrix(late_combined_predicted, late_combined_predicted)\n",
    "\n",
    "classes = np.ndarray([0,1,2,3])\n",
    "\n",
    "print(f'Late Fusion Confusion Matrix with F1 Score: {late_f1}')\n",
    "print('--------------------------------')\n",
    "plot_confusion_matrix(late_cm, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
